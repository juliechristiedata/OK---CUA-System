{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ab3f1e-c8c8-4ac6-bee9-1da1cf53e891",
   "metadata": {},
   "source": [
    "![logo](https://resolvephilly.org/themes/custom/resolvephl-ci/logo.svg)\n",
    "\n",
    "# Scraping and standardizing Pennsylvania Act 146 Quarterly Reports\n",
    "\n",
    "**Author:** Julie Christie | Director of Data & Impact\n",
    "\n",
    "**Partnering Team:** Our Kids\n",
    "\n",
    "**Date:** March 28, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05127cca-9b13-4b04-8cae-54c0cb83f456",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Pennsylvania publishes reports on child fatalities and near fatalities that the state determined were a result of child abuse. The reports include the age, sex, county, and date of the incident, as well as whether the family was previously known to the local department of human/family services. The detailed reports are all published online, however scraping those may prove to be more complicated than scraping the quarterly reports. These reports are written in a narrative format that is consistent throughout the entire quarterly report. The structure of these narrative summaries can change between reports, making scraping this also complicated.\n",
    "\n",
    "### Goal of Analysis\n",
    "\n",
    "Specifically, Resolve is looking to understand the frequency at which children who experience abuse that results in their death/near death are already known to the system. We are exploring these rates at the county level to understand what the statewide trend is, and how Philadelphia measures up to that trend.\n",
    "\n",
    "### Glossary\n",
    "\n",
    "-   **Act 146** -- *\"Act 146 of 2006 went into effect on May 8, 2007. A major provision of this law requires that the department prepare a non-identifying summary for the governor and the General Assembly of findings for each case of substantiated child abuse or neglect that has resulted in a child fatality or near fatality.\"*\n",
    "-   **Near fatality** -- *Definition TKTK, which is determined by the \"certifying physician\" from the state.*\n",
    "-   **DA De-certification** -- *This gets assigned to a report when the District Attorney determines that the incident was not a result of child abuse.*\n",
    "\n",
    "### Data\n",
    "\n",
    "-   [Child Fatality/Near Fatality Quarterly Reports](https://www.pa.gov/en/agencies/dhs/resources/data-reports/quarterly-summaries-child-abuse.html) --- A collection of brief summaries of fatalities/near fatalities of children due to abuse. | No metadata available\n",
    "\n",
    "### Tools\n",
    "\n",
    "-   [Python](python.org) -- *Base code to facilitate scraping*\n",
    "-   [Pandas](https://pandas.pydata.org/) -- *More robust data anlysis*\n",
    "-   [Regex](https://developers.google.com/edu/python/regular-expressions) -- *Regular Expressions, or Regex, to parse out patterns of characters*\n",
    "-   [PDF Plumber](https://github.com/jsvine/pdfplumber) -- *Parse information from .pdf files*\n",
    "-   [Excel](https://www.microsoft.com/en-us/microsoft-365/p/excel/cfq7ttc0hr4r?activetab=pivot:overviewtab) -- *Clean and analyze tabulated data*\n",
    "\n",
    "### Limitations\n",
    "- A \"certifying pysician\" makes an individual call on whether a child's death/near death is the result of abuse, meaning that human error may result in cases not being documented in these reports\n",
    "- Child fatalities and near fatalities as a result of abuse are an incredibly small and extreme subset of the overall abuse that children face. This analysis does not constitute a full picture, but rather is a snapshot of what the state deemed the most egregious cases.\n",
    "- These quarterly reports may not contain all instances. A previous scrape of individual reports rendered about 2,400 reports. This scrape yielded TKTK summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75472dc-d4fe-4cc4-9a5c-4d9dfa9a4fad",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c04df14",
   "metadata": {},
   "source": [
    "1. Download all the reports from the Pennsylvania DHS site. (See Data for direct link.)\n",
    "2. Rename the files to have a standard strucutre.\n",
    "3. Make sure that you convert anything that was downloaded as a `.docx` file into a `.pdf` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13ed6d4",
   "metadata": {},
   "source": [
    "### Overview of process\n",
    "\n",
    "Each report is put together with a basic structure of: \n",
    "\n",
    "```\n",
    "Fatalities\n",
    "    County 1\n",
    "        1. Incident description\n",
    "        2. Incident description\n",
    "        3. Incident description\n",
    "        ...\n",
    "    County 2 \n",
    "    ...\n",
    "    County 67\n",
    "        ...\n",
    "\n",
    "Near Fatalities\n",
    "    County 1\n",
    "        1. Incident description\n",
    "        2. Incident description\n",
    "        3. Incident description\n",
    "        ...\n",
    "    County 2 \n",
    "    ...\n",
    "    County 67\n",
    "        ...\n",
    "```\n",
    "\n",
    "And within that, each incident description is roughly structured as:\n",
    "\n",
    "> 1. A `##-age-old` `sex` child `died/nearly died` on `date` as a result of .... `Agency Name` indicated the report on ... naming the victim child's `identifier for relationship` as the perpetrator(s). ... Further details of the incident are written out. ...  The family `was/was not known` to child welfare.\n",
    "\n",
    "However, this phrasing changes to things like \"On `date` a `##-age-old` `sex` child `died/nearly died` ...\"\n",
    "\n",
    "The regex must also take into account any instances where a sibiling is mentioned with a similar structure, like \"the victim's ##-age-old sibling was present at the time.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1670d882-3ba4-4875-bd73-336f68c6b2c0",
   "metadata": {},
   "source": [
    "### Prepare Python Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e710e746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in ./cuaenvironment/lib/python3.12/site-packages (0.11.0)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in ./cuaenvironment/lib/python3.12/site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in ./cuaenvironment/lib/python3.12/site-packages (from pdfplumber) (10.3.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in ./cuaenvironment/lib/python3.12/site-packages (from pdfplumber) (4.30.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in ./cuaenvironment/lib/python3.12/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in ./cuaenvironment/lib/python3.12/site-packages (from pdfminer.six==20231228->pdfplumber) (42.0.7)\n",
      "Requirement already satisfied: cffi>=1.12 in ./cuaenvironment/lib/python3.12/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\n",
      "Requirement already satisfied: pycparser in ./cuaenvironment/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7c9aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas\n",
    "# pip install pypdf2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6ed53b-9a9d-4c54-9b3f-96ed32c9e202",
   "metadata": {},
   "source": [
    "Import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c17e0ad5-fb7e-4d7e-bd2d-bddf8b2b380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber       # PDF Plumber to scrape throught .pdf files\n",
    "import re               # Regular Expressions\n",
    "import csv              # Comma Separated Values\n",
    "import glob             # To make a list of all files in a folder\n",
    "from PyPDF2 import PdfReader    # To import file reader\n",
    "import os               # To help with accessing directories\n",
    "import argparse         # TKTTKKTK\n",
    "\n",
    "# import pandas as pd\n",
    "# from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db9a9d",
   "metadata": {},
   "source": [
    "### Repair PDF files\n",
    "\n",
    "Some of the files may be broken when converting from a Word document to a PDF document.\n",
    "\n",
    "Source: https://stackoverflow.com/questions/58807673/best-way-to-check-the-pdf-file-is-corrupt-using-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d4eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that \n",
    "def check_file(fullfile):\n",
    "    with open(fullfile, 'rb') as f:\n",
    "        try:\n",
    "            pdf = PdfReader(f)\n",
    "            info = pdf.metadata\n",
    "            if info:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            return False\n",
    "\n",
    "\n",
    "def search_files(dirpath: str) -> pd.DataFrame:\n",
    "    pwdpath = os.path.dirname(os.path.realpath(__file__))\n",
    "    print(\"Running path : %s\" %pwdpath)\n",
    "    files = []\n",
    "    if os.access(dirpath, os.R_OK):\n",
    "        print(\"Path %s validation OK \\n\" %dirpath)\n",
    "        listfiles = os.listdir(dirpath)\n",
    "        for f in listfiles:\n",
    "            fullfile = os.path.join(dirpath, f)\n",
    "            if check_file(fullfile):\n",
    "                print(\"OK \" + fullfile + \"\\n################\")\n",
    "                files.append((f, fullfile, 'good'))\n",
    "            else:\n",
    "                print(\"ERROR \" + fullfile + \"\\n################\")\n",
    "                files.append((f, fullfile, 'corrupted'))\n",
    "    else:\n",
    "        print(\"Path is not valid\")\n",
    "\n",
    "    df = pd.DataFrame(files, columns=['filename', 'fullpath', 'status'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    df = search_files(args.dirpath)\n",
    "    df.to_csv(args.output, index=False)\n",
    "    print(f'Final report saved to {args.output}')\n",
    "    print(df['status'].value_counts())\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\" Command line script for finding corrupted PDFs in a directory. \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--dirpath', type=str, required=True, help='Path to directory containing PDFs.')\n",
    "    parser.add_argument('--output', type=str, required=True, help='Path to output CSV file.')\n",
    "    args = parser.parse_args()\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c871b4d",
   "metadata": {},
   "source": [
    "### Parse incidents into a `.csv` file\n",
    "\n",
    "This code was written by [Maggie Lee](http://maggielee.net/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1cd4f07",
   "metadata": {},
   "outputs": [
    {
     "ename": "PDFSyntaxError",
     "evalue": "No /Root object! - Is this really a PDF?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPDFSyntaxError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#  this opens the pdf, and loops through every page in the pdf and puts the text of all pages together in `text_of_a_single_pdf`\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpdfplumber\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pdf:\n\u001b[1;32m     18\u001b[0m \tpages \u001b[38;5;241m=\u001b[39m pdf\u001b[38;5;241m.\u001b[39mpages\n\u001b[1;32m     19\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pages:\n",
      "File \u001b[0;32m~/Desktop/OK — CUA System/cuaenvironment/lib/python3.12/site-packages/pdfplumber/pdf.py:95\u001b[0m, in \u001b[0;36mPDF.open\u001b[0;34m(cls, path_or_fp, pages, laparams, password, strict_metadata, repair, gs_path)\u001b[0m\n\u001b[1;32m     92\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlaparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlaparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpassword\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_is_external\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_is_external\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PSException:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream_is_external:\n",
      "File \u001b[0;32m~/Desktop/OK — CUA System/cuaenvironment/lib/python3.12/site-packages/pdfplumber/pdf.py:45\u001b[0m, in \u001b[0;36mPDF.__init__\u001b[0;34m(self, stream, stream_is_external, path, pages, laparams, password, strict_metadata)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlaparams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m laparams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m LAParams(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlaparams)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpassword \u001b[38;5;241m=\u001b[39m password\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc \u001b[38;5;241m=\u001b[39m \u001b[43mPDFDocument\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPDFParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpassword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrsrcmgr \u001b[38;5;241m=\u001b[39m PDFResourceManager()\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Desktop/OK — CUA System/cuaenvironment/lib/python3.12/site-packages/pdfminer/pdfdocument.py:752\u001b[0m, in \u001b[0;36mPDFDocument.__init__\u001b[0;34m(self, parser, password, caching, fallback)\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 752\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PDFSyntaxError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo /Root object! - Is this really a PDF?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcatalog\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m LITERAL_CATALOG:\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mSTRICT:\n",
      "\u001b[0;31mPDFSyntaxError\u001b[0m: No /Root object! - Is this really a PDF?"
     ]
    }
   ],
   "source": [
    "# Set location of file to scrape and destination file for data\n",
    "\n",
    "directory = r\"/Users/juliechristie/Desktop/OK — CUA System/act_33_quarterly\"\n",
    "\n",
    "for filename in glob.glob(f\"{directory}/*\"):\n",
    "\n",
    "\tcsv_output_file = 'incidents.csv'\n",
    "\n",
    "\ttext_of_a_single_pdf = ''\n",
    "\n",
    "\t# output is going to be a list of lists\n",
    "\t#  each list in there will be a list of output: report type, county and narrative\n",
    "\toutput = []\n",
    "\n",
    "\t#  this opens the pdf, and loops through every page in the pdf and puts the text of all pages together in `text_of_a_single_pdf`\n",
    "\n",
    "\twith pdfplumber.open(filename) as pdf:\n",
    "\t\tpages = pdf.pages\n",
    "\t\tfor page in pages:\n",
    "\t\t\ttext = (page.extract_text())\n",
    "\t\t\ttext_of_a_single_pdf = text_of_a_single_pdf + text\n",
    "\n",
    "\n",
    "\ttext_as_lines = text_of_a_single_pdf.split('\\n')\n",
    "\n",
    "\t#  default report type will be fatality, this assumes fatalities always come first\n",
    "\treport_type = 'fatality'\n",
    "\tcounty = ''\n",
    "\tnarrative = ''\n",
    "\tnew_row = []\n",
    "\tfor line in text_as_lines:\n",
    "\n",
    "\t\tif 'Near Fatalities:' in line:\n",
    "\t\t\t# when parsing, if you come to the line 'near fatalities', the variable 'report_type' will change\n",
    "\t\t\treport_type = 'near fatality'\n",
    "\t\telif 'County:' in line:\n",
    "\t\t\t# 'same with county, the county will stay the same, line after line, until the parser sees a new county name\n",
    "\t\t\tcounty = line\n",
    "\t\t# Compare the beginning of the line with a Regex expression that identifies all the different types of numbered line starts in the document. \n",
    "\t\telif re.search(r\"(?:\\d{1,2}|\\d{1,2}-\\d{1,2})(?:(?:\\.|(?:\\)))|\\.(?:\\)))\", line):\n",
    "\t\t\t# if this happens, if you hit a numbered paragraph, a new row will need to be logged as output, so let's log the old row\n",
    "\t\t\tif 'Fatalities: ' in new_row:\n",
    "\t\t\t\t# this is just to kill the row it's trying to make out of the very first line of the file\n",
    "\t\t\t\tpass\n",
    "\t\t\telse:\n",
    "\t\t\t\toutput.append(new_row)\n",
    "\t\t\t#  and start a new row\n",
    "\t\t\tnew_row = [report_type, county]\n",
    "\t\t\tnarrative = line\n",
    "\t\telse:\n",
    "\t\t\tnarrative = narrative + line\n",
    "\t\t\tnew_row = [report_type, county, narrative]\n",
    "\n",
    "#  then log the very last paragraph\n",
    "output.append(new_row)\n",
    "\n",
    "\n",
    "\n",
    "with open(csv_output_file, 'w') as f:\n",
    "\twriter = csv.writer(f)\n",
    "\tfor row in output:\n",
    "\t\twriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec58718d",
   "metadata": {},
   "source": [
    "Create the column names for the data that you are extracting from the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df312dcd-4239-497e-9ed1-751a4b99ff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "Line = namedtuple('Line', 'fatality county age sex date cause perpetrator indicated_date known_to_agency')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161293b5",
   "metadata": {},
   "source": [
    "Create a list of all 67 counties in PA to match with the different headers of the reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf71956",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_counties = [\"Adams\", \"Allegheny\", \"Armstrong\", \"Beaver\", \"Bedford\", \"Berks\", \"Blair\", \"Bradford\", \"Bucks\", \"Butler\", \"Cambria\", \"Cameron\", \"Carbon\", \"Centre\", \"Chester\", \"Clarion\", \"Clearfield\", \"Clinton\", \"Columbia\", \"Crawford\", \"Cumberland\", \"Dauphin\", \"Delaware\", \"Elk\", \"Erie\", \"Fayette\", \"Forest\", \"Franklin\", \"Fulton\", \"Greene\", \"Huntingdon\", \"Indiana\", \"Jefferson\", \"Juniata\", \"Lackawanna\", \"Lancaster\", \"Lawrence\", \"Lebanon\", \"Lehigh\", \"Luzerne\", \"Lycoming\", \"McKean\", \"Mercer\", \"Mifflin\", \"Monroe\", \"Montgomery\", \"Montour\", \"Northampton\", \"Northumberland\", \"Perry\", \"Philadelphia\", \"Pike\", \"Potter\", \"Schuylkill\", \"Snyder\", \"Somerset\", \"Sullivan\", \"Susquehanna\", \"Tioga\", \"Union\", \"Venango\", \"Warren\", \"Washington\", \"Wayne\", \"Westmoreland\", \"Wyoming\", \"York\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950cc703",
   "metadata": {},
   "source": [
    "All of the documents are organized by listing whether the case was a fatality as nested headers. The below code sets up a regex function that identifies the headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fatality_re = re.compile(r'(Fatalities|Near Fatalities)')\n",
    "line_re = re.compile(r'\\d{1,2}((\\.|(\\)))|\\.(\\)))\\s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c9a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_re.search('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b285629",
   "metadata": {},
   "source": [
    "Set the file for your search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff0f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'act_33_quarterly/1st Quarter Summaries of Child Fatalities Near Fatalities (1).pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f78a8",
   "metadata": {},
   "source": [
    "Parse out the data in the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2620717",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "with pdfplumber.open(file) as pdf:\n",
    "    pages = pdf.pages\n",
    "    for page in pdf.pages:\n",
    "        text = page.extract_text()\n",
    "        for line in text.split('(\\n|\\r)\\d{1,2}((\\.|(\\)))|\\.(\\)))\\s'):\n",
    "            print(line)\n",
    "            fatality_set = fatality_re.search(line)\n",
    "            if fatality_set:\n",
    "                fatality = fatality_set.group(1)\n",
    "\n",
    "            elif line.startswith(tuple(pa_counties)):\n",
    "                county = line\n",
    "\n",
    "            elif line_re.search(line):\n",
    "                items = line.split()\n",
    "                lines.append(Line(vend_no, vend_name, doctype, *items))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
