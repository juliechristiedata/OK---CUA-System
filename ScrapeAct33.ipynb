{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ab3f1e-c8c8-4ac6-bee9-1da1cf53e891",
   "metadata": {},
   "source": [
    "![logo](https://resolvephilly.org/themes/custom/resolvephl-ci/logo.svg)\n",
    "\n",
    "# Scraping and standardizing Pennsylvania Act 146 Quarterly Reports\n",
    "\n",
    "**Author:** Julie Christie | Director of Data & Impact\n",
    "\n",
    "**Partnering Team:** Our Kids\n",
    "\n",
    "**Date:** March 28, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05127cca-9b13-4b04-8cae-54c0cb83f456",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Pennsylvania publishes reports on child fatalities and near fatalities that the state determined were a result of child abuse. The reports include the age, sex, county, and date of the incident, as well as whether the family was previously known to the local department of human/family services. The detailed reports are all published online, however scraping those may prove to be more complicated than scraping the quarterly reports. These reports are written in a narrative format that is consistent throughout the entire quarterly report. The structure of these narrative summaries can change between reports, making scraping this also complicated.\n",
    "\n",
    "### Goal of Analysis\n",
    "\n",
    "Specifically, Resolve is looking to understand the frequency at which children who experience abuse that results in their death/near death are already known to the system. We are exploring these rates at the county level to understand what the statewide trend is, and how Philadelphia measures up to that trend.\n",
    "\n",
    "### Glossary\n",
    "\n",
    "-   **Act 146** -- *\"Act 146 of 2006 went into effect on May 8, 2007. A major provision of this law requires that the department prepare a non-identifying summary for the governor and the General Assembly of findings for each case of substantiated child abuse or neglect that has resulted in a child fatality or near fatality.\"*\n",
    "-   **Near fatality** -- *Definition TKTK, which is determined by the \"certifying physician\" from the state.*\n",
    "-   **DA De-certification** -- *This gets assigned to a report when the District Attorney determines that the incident was not a result of child abuse.*\n",
    "\n",
    "### Data\n",
    "\n",
    "-   [Child Fatality/Near Fatality Quarterly Reports](https://www.pa.gov/en/agencies/dhs/resources/data-reports/quarterly-summaries-child-abuse.html) --- A collection of brief summaries of fatalities/near fatalities of children due to abuse. | No metadata available\n",
    "\n",
    "### Tools\n",
    "\n",
    "-   [Python](python.org) -- *Base code to facilitate scraping*\n",
    "-   [Pandas](https://pandas.pydata.org/) -- *More robust data anlysis*\n",
    "-   [Regex](https://developers.google.com/edu/python/regular-expressions) -- *Regular Expressions, or Regex, to parse out patterns of characters*\n",
    "-   [PDF Plumber](https://github.com/jsvine/pdfplumber) -- *Parse information from .pdf files*\n",
    "-   [Excel](https://www.microsoft.com/en-us/microsoft-365/p/excel/cfq7ttc0hr4r?activetab=pivot:overviewtab) -- *Clean and analyze tabulated data*\n",
    "\n",
    "### Limitations\n",
    "- A \"certifying pysician\" makes an individual call on whether a child's death/near death is the result of abuse, meaning that human error may result in cases not being documented in these reports\n",
    "- Child fatalities and near fatalities as a result of abuse are an incredibly small and extreme subset of the overall abuse that children face. This analysis does not constitute a full picture, but rather is a snapshot of what the state deemed the most egregious cases.\n",
    "- These quarterly reports may not contain all instances. A previous scrape of individual reports rendered about 2,400 reports. This scrape yielded TKTK summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75472dc-d4fe-4cc4-9a5c-4d9dfa9a4fad",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c04df14",
   "metadata": {},
   "source": [
    "1. Download all the reports from the Pennsylvania DHS site. (See Data for direct link.)\n",
    "2. Rename the files to have a standard strucutre.\n",
    "3. Make sure that you convert anything that was downloaded as a `.docx` file into a `.pdf` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13ed6d4",
   "metadata": {},
   "source": [
    "### Overview of process\n",
    "\n",
    "Each report is put together with a basic structure of: \n",
    "\n",
    "```\n",
    "Fatalities\n",
    "    County 1\n",
    "        1. Incident description\n",
    "        2. Incident description\n",
    "        3. Incident description\n",
    "        ...\n",
    "    County 2 \n",
    "    ...\n",
    "    County 67\n",
    "        ...\n",
    "\n",
    "Near Fatalities\n",
    "    County 1\n",
    "        1. Incident description\n",
    "        2. Incident description\n",
    "        3. Incident description\n",
    "        ...\n",
    "    County 2 \n",
    "    ...\n",
    "    County 67\n",
    "        ...\n",
    "```\n",
    "\n",
    "And within that, each incident description is roughly structured as:\n",
    "\n",
    "> 1. A `##-age-old` `sex` child `died/nearly died` on `date` as a result of .... `Agency Name` indicated the report on ... naming the victim child's `identifier for relationship` as the perpetrator(s). ... Further details of the incident are written out. ...  The family `was/was not known` to child welfare.\n",
    "\n",
    "However, this phrasing changes to things like \"On `date` a `##-age-old` `sex` child `died/nearly died` ...\"\n",
    "\n",
    "The regex must also take into account any instances where a sibiling is mentioned with a similar structure, like \"the victim's ##-age-old sibling was present at the time.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1670d882-3ba4-4875-bd73-336f68c6b2c0",
   "metadata": {},
   "source": [
    "### Prepare Python Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e710e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7c9aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas\n",
    "# pip install pypdf2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6ed53b-9a9d-4c54-9b3f-96ed32c9e202",
   "metadata": {},
   "source": [
    "Import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c17e0ad5-fb7e-4d7e-bd2d-bddf8b2b380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber       # PDF Plumber to scrape throught .pdf files\n",
    "import re               # Regular Expressions\n",
    "import csv              # Comma Separated Values\n",
    "# import glob             # To make a list of all files in a folder\n",
    "import os               # To help with accessing directories\n",
    "\n",
    "# from PyPDF2 import PdfReader    # To import file reader\n",
    "\n",
    "# import argparse         # TKTTKKTK\n",
    "# import pandas as pd\n",
    "\n",
    "# from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db9a9d",
   "metadata": {},
   "source": [
    "### Repair PDF files\n",
    "\n",
    "Some of the files may be broken when converting from a Word document to a PDF document.\n",
    "\n",
    "Source: https://stackoverflow.com/questions/58807673/best-way-to-check-the-pdf-file-is-corrupt-using-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d4eba2",
   "metadata": {},
   "source": [
    "# Create a function that checks if a PDF is broken\n",
    "def check_file(fullfile):\n",
    "    with open(fullfile, 'rb') as f:\n",
    "        try:\n",
    "            pdf = PdfReader(f)\n",
    "            info = pdf.metadata\n",
    "            if info:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            return False\n",
    "\n",
    "# Create a log of all files in a directory and their corruption status\n",
    "def search_files(dirpath: str) -> pd.DataFrame:\n",
    "    pwdpath = os.path.dirname(os.path.realpath(\"/Users/juliechristie/Desktop/OK â€” CUA System/act_33_quarterly/act146_2011_Q1.pdf\"))\n",
    "    print(\"Running path : %s\" %pwdpath)\n",
    "    files = []\n",
    "    if os.access(dirpath, os.R_OK):\n",
    "        print(\"Path %s validation OK \\n\" %dirpath)\n",
    "        listfiles = os.listdir(dirpath)\n",
    "        for f in listfiles:\n",
    "            fullfile = os.path.join(dirpath, f)\n",
    "            if check_file(fullfile):\n",
    "                print(\"OK \" + fullfile + \"\\n################\")\n",
    "                files.append((f, fullfile, 'good'))\n",
    "            else:\n",
    "                print(\"ERROR \" + fullfile + \"\\n################\")\n",
    "                files.append((f, fullfile, 'corrupted'))\n",
    "    else:\n",
    "        print(\"Path is not valid\")\n",
    "\n",
    "    df = pd.DataFrame(files, columns=['filename', 'fullpath', 'status'])\n",
    "    return df\n",
    "\n",
    "# Print the log to a csv file\n",
    "def main(args):\n",
    "    df = search_files(args.dirpath)\n",
    "    df.to_csv(args.output, index=False)\n",
    "    print(f'Final report saved to {args.output}')\n",
    "    print(df['status'].value_counts())\n",
    "\n",
    "# Combine things???\n",
    "if __name__ == '__main__':\n",
    "    \"\"\" Command line script for finding corrupted PDFs in a directory. \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--dirpath', type=str, required=True, help='Path to directory containing PDFs.')\n",
    "    parser.add_argument('--output', type=str, required=True, help='Path to output CSV file.')\n",
    "    args = parser.parse_args()\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c871b4d",
   "metadata": {},
   "source": [
    "### Parse incidents into a `.csv` file\n",
    "\n",
    "This code was written by [Maggie Lee](http://maggielee.net/)\n",
    "\n",
    "This code needs to be improved to have a loop, however in the interest of time,  I will be manually creating a new csv for each report. Not all of the parses will be accurate, and I will manually fix them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e1cd4f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set location of file to scrape and destination file for data\n",
    "\n",
    "#directory = r\"/Users/juliechristie/Desktop/OK â€” CUA System/act_33_quarterly\"\n",
    "\n",
    "#for filename in glob.glob(f\"{directory}/*\"):\n",
    "\n",
    "\n",
    "filename = 'act_33_quarterly/act146_2023_Q1.pdf'\n",
    "\n",
    "# Get the base name without the extension\n",
    "base_name = os.path.splitext(filename)[0]\n",
    "\n",
    "# Create the CSV output file name with a .csv extension\n",
    "csv_output_file = f'{base_name}.csv'\n",
    "\n",
    "text_of_a_single_pdf = ''\n",
    "\n",
    "# output is going to be a list of lists\n",
    "# each list in there will be a list of output: report type, county and narrative\n",
    "output = []\n",
    "\n",
    "#  this opens the pdf, and loops through every page in the pdf and puts the text of all pages together in `text_of_a_single_pdf`\n",
    "\n",
    "with pdfplumber.open(filename) as pdf:\n",
    "\tpages = pdf.pages\n",
    "\tfor page in pages:\n",
    "\t\ttext = (page.extract_text())\n",
    "\t\ttext_of_a_single_pdf = text_of_a_single_pdf + text\n",
    "\n",
    "\n",
    "text_as_lines = text_of_a_single_pdf.split('\\n')\n",
    "\n",
    "#  default report type will be fatality, this assumes fatalities always come first\n",
    "report_type = 'fatality'\n",
    "county = ''\n",
    "narrative = ''\n",
    "new_row = []\n",
    "for line in text_as_lines:\n",
    "\n",
    "\tif 'Near Fatalities:' in line:\n",
    "\t\t# when parsing, if you come to the line 'near fatalities', the variable 'report_type' will change\n",
    "\t\treport_type = 'near fatality'\n",
    "\telif 'County:' in line:\n",
    "\t\t# 'same with county, the county will stay the same, line after line, until the parser sees a new county name\n",
    "\t\tcounty = line\n",
    "\t# Compare the beginning of the line with a Regex expression that identifies all the different types of numbered line starts in the document. \n",
    "\telif re.search(r\"(?:\\d{1,2}|\\d{1,2}-\\d{1,2})(?:(?:\\.|(?:\\)))|\\.(?:\\)))\", line):\n",
    "\t\t# if this happens, if you hit a numbered paragraph, a new row will need to be logged as output, so let's log the old row\n",
    "\t\tif 'Fatalities: ' in new_row:\n",
    "\t\t\t# this is just to kill the row it's trying to make out of the very first line of the file\n",
    "\t\t\tpass\n",
    "\t\telse:\n",
    "\t\t\toutput.append(new_row)\n",
    "\t\t#  and start a new row\n",
    "\t\tnew_row = [report_type, county]\n",
    "\t\tnarrative = line\n",
    "\telse:\n",
    "\t\tnarrative = narrative + line\n",
    "\t\tnew_row = [report_type, county, narrative]\n",
    "\n",
    "#  then log the very last paragraph\n",
    "output.append(new_row)\n",
    "\n",
    "\n",
    "\n",
    "with open(csv_output_file, 'w') as f:\n",
    "\twriter = csv.writer(f)\n",
    "\tfor row in output:\n",
    "\t\twriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec58718d",
   "metadata": {},
   "source": [
    "Create the column names for the data that you are extracting from the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df312dcd-4239-497e-9ed1-751a4b99ff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "Line = namedtuple('Line', 'fatality county age sex date cause perpetrator indicated_date known_to_agency')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161293b5",
   "metadata": {},
   "source": [
    "Create a list of all 67 counties in PA to match with the different headers of the reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf71956",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_counties = [\"Adams\", \"Allegheny\", \"Armstrong\", \"Beaver\", \"Bedford\", \"Berks\", \"Blair\", \"Bradford\", \"Bucks\", \"Butler\", \"Cambria\", \"Cameron\", \"Carbon\", \"Centre\", \"Chester\", \"Clarion\", \"Clearfield\", \"Clinton\", \"Columbia\", \"Crawford\", \"Cumberland\", \"Dauphin\", \"Delaware\", \"Elk\", \"Erie\", \"Fayette\", \"Forest\", \"Franklin\", \"Fulton\", \"Greene\", \"Huntingdon\", \"Indiana\", \"Jefferson\", \"Juniata\", \"Lackawanna\", \"Lancaster\", \"Lawrence\", \"Lebanon\", \"Lehigh\", \"Luzerne\", \"Lycoming\", \"McKean\", \"Mercer\", \"Mifflin\", \"Monroe\", \"Montgomery\", \"Montour\", \"Northampton\", \"Northumberland\", \"Perry\", \"Philadelphia\", \"Pike\", \"Potter\", \"Schuylkill\", \"Snyder\", \"Somerset\", \"Sullivan\", \"Susquehanna\", \"Tioga\", \"Union\", \"Venango\", \"Warren\", \"Washington\", \"Wayne\", \"Westmoreland\", \"Wyoming\", \"York\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950cc703",
   "metadata": {},
   "source": [
    "All of the documents are organized by listing whether the case was a fatality as nested headers. The below code sets up a regex function that identifies the headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fatality_re = re.compile(r'(Fatalities|Near Fatalities)')\n",
    "line_re = re.compile(r'\\d{1,2}((\\.|(\\)))|\\.(\\)))\\s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c9a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_re.search('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b285629",
   "metadata": {},
   "source": [
    "Set the file for your search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff0f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'act_33_quarterly/1st Quarter Summaries of Child Fatalities Near Fatalities (1).pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f78a8",
   "metadata": {},
   "source": [
    "Parse out the data in the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2620717",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "with pdfplumber.open(file) as pdf:\n",
    "    pages = pdf.pages\n",
    "    for page in pdf.pages:\n",
    "        text = page.extract_text()\n",
    "        for line in text.split('(\\n|\\r)\\d{1,2}((\\.|(\\)))|\\.(\\)))\\s'):\n",
    "            print(line)\n",
    "            fatality_set = fatality_re.search(line)\n",
    "            if fatality_set:\n",
    "                fatality = fatality_set.group(1)\n",
    "\n",
    "            elif line.startswith(tuple(pa_counties)):\n",
    "                county = line\n",
    "\n",
    "            elif line_re.search(line):\n",
    "                items = line.split()\n",
    "                lines.append(Line(vend_no, vend_name, doctype, *items))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
