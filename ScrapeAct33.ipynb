{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ab3f1e-c8c8-4ac6-bee9-1da1cf53e891",
   "metadata": {},
   "source": [
    "![logo](https://resolvephilly.org/themes/custom/resolvephl-ci/logo.svg)\n",
    "\n",
    "# Scraping and standardizing Pennsylvania Act 146 Individual Reports\n",
    "\n",
    "**Author:** Julie Christie | Director of Data & Impact\n",
    "\n",
    "**Partnering Team:** Our Kids\n",
    "\n",
    "**Date:** March 28, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05127cca-9b13-4b04-8cae-54c0cb83f456",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Pennsylvania publishes reports on child fatalities and near fatalities as a result of child abuse. The reports include the age, sex, county, and date of the incident, as well as whether the family was known to the local department of human/family services in the 16 months preceding the incident. The detailed reports are organized online in a way that can be scraped for some, but not all of the information. The first page of the `.pdf` reports contain the rest of the necessary information.\n",
    "\n",
    "### Goal of Analysis\n",
    "\n",
    "Specifically, Resolve is looking to understand the frequency at which children who experience abuse that results in their death/near death are already known to the system. We are exploring these rates at the county level to understand what the statewide trend is, and whether Philadelphia exceeds that trend.\n",
    "\n",
    "### Glossary\n",
    "\n",
    "-   **Act 146** -- *\"Act 146 of 2006 went into effect on May 8, 2007. A major provision of this law requires that the department prepare a non-identifying summary for the governor and the General Assembly of findings for each case of substantiated child abuse or neglect that has resulted in a child fatality or near fatality.\"*\n",
    "-   **Near fatality** -- *Definition TKTK*\n",
    "-   **DA De-certification** -- *This gets assigned to a report when the District Attorney determines that the incident was not a result of child abuse.*\n",
    "\n",
    "### Data\n",
    "\n",
    "-   [Child Fatality/Near Fatality Reports](https://www.dhs.pa.gov/docs/OCYF/Pages/Fatality-Reports.aspx) --- A table of the reports with some information and URLs to the actual reports. | No metadata available\n",
    "\n",
    "### Tools\n",
    "\n",
    "-   [Python](python.org) -- *Base code to facilitate scraping*\n",
    "-   [Pandas](https://pandas.pydata.org/) -- *More robust data anlysis*\n",
    "-   [Regex](https://developers.google.com/edu/python/regular-expressions) -- *Regular Expressions, or Regex, to parse out patterns of characters*\n",
    "-   [PDF Plumber](https://github.com/jsvine/pdfplumber) -- *Parse information from .pdf files*\n",
    "-   [Web Scraper](https://www.webscraper.io/documentation?utm_source=extension&utm_medium=popup) -- *Scrape data from a webpage*\n",
    "-   [Excel](https://www.microsoft.com/en-us/microsoft-365/p/excel/cfq7ttc0hr4r?activetab=pivot:overviewtab) -- *Clean and analyze tabulated data*\n",
    "\n",
    "### Limitations\n",
    "- A \"certifying pysician\" makes an individual call on whether a child's death/near death is the result of abuse, meaning that human error may result in cases not being documented in these reports\n",
    "- Child fatalities and near fatalities as a result of abuse are an incredibly small and extreme subset of the overall abuse that children face.\n",
    "- Counties not recorded in scraped data pre-2016; 764 cases need counties assigned\n",
    "- 922 Reports have URLs that indicate they have been de-certified and therefore have no report details. These all share one of 6 common URLs:\n",
    "1. https://www.dhs.pa.gov/docs/OCYF/Pages/DA-Certification.aspx\n",
    "2. https://auth-agency.pa.egov.com/sites/HumanServices/docs/OCYF/Pages/Unlinked-Report.aspx\n",
    "3. https://www.dhs.pa.gov/docs/OCYF/Pages/Unlinked-Report.aspx\n",
    "4. https://auth-agency.pa.egov.com/sites/HumanServices/docs/OCYF/Pages/DA-Certification.aspx\n",
    "5. https://www.dhs.pa.gov/docs/OCYF/Pages/Decertification.aspx\n",
    "6. https://auth-agency.pa.egov.com/sites/HumanServices/docs/OCYF/Pages/Decertification.aspx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75472dc-d4fe-4cc4-9a5c-4d9dfa9a4fad",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086485e3-a425-47dc-b967-a73861f179a9",
   "metadata": {},
   "source": [
    "### Scrape reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42baccd-7f6b-4244-a397-fb0cd3e0ba97",
   "metadata": {},
   "source": [
    "1. Use Web Scraper to extract report URLs and associated data into a `.csv` file. This creates a new row of data for each report, and each column respectively. The sitemap is:\n",
    "\n",
    "```\n",
    "{\"_id\":\"pa_33_reports\",\"startUrl\":[\"https://www.dhs.pa.gov/docs/OCYF/Pages/Fatality-Reports.aspx\"],\"selectors\":[{\"clickActionType\":\"real\",\"clickElementSelector\":\"#ctl00_ctl49_g_2f5406ff_66ab_4f5d_b7c7_f984206b2ab7_ddlPageSizer > option:nth-child(5)\",\"clickElementUniquenessType\":\"uniqueText\",\"clickType\":\"clickOnce\",\"delay\":2000,\"discardInitialElements\":\"do-not-discard\",\"id\":\"select_all\",\"multiple\":false,\"parentSelectors\":[\"_root\"],\"selector\":\"_parent_\",\"type\":\"SelectorElementClick\"},{\"id\":\"report\",\"multiple\":true,\"parentSelectors\":[\"select_all\"],\"selector\":\"tr:nth-of-type(n+2)\",\"type\":\"SelectorElement\"},{\"id\":\"info\",\"multiple\":false,\"parentSelectors\":[\"report\"],\"regex\":\"\",\"selector\":\"td:nth-of-type(1)\",\"type\":\"SelectorText\"},{\"id\":\"report_id\",\"multiple\":false,\"parentSelectors\":[\"report\"],\"regex\":\"\",\"selector\":\"td:nth-of-type(2)\",\"type\":\"SelectorText\"},{\"id\":\"fatality\",\"multiple\":false,\"parentSelectors\":[\"report\"],\"regex\":\"\",\"selector\":\"td:nth-of-type(3)\",\"type\":\"SelectorText\"},{\"id\":\"year\",\"multiple\":false,\"parentSelectors\":[\"report\"],\"regex\":\"\",\"selector\":\"td:nth-of-type(4)\",\"type\":\"SelectorText\"},{\"id\":\"date\",\"multiple\":false,\"parentSelectors\":[\"report\"],\"regex\":\"\",\"selector\":\"td:nth-of-type(5)\",\"type\":\"SelectorText\"},{\"id\":\"DA_Cert\",\"multiple\":false,\"parentSelectors\":[\"report\"],\"regex\":\"\",\"selector\":\"td:nth-of-type(6)\",\"type\":\"SelectorText\"},{\"id\":\"report_url\",\"linkType\":\"linkFromHref\",\"multiple\":false,\"parentSelectors\":[\"report\"],\"selector\":\"a\",\"type\":\"SelectorLink\"}]}\n",
    "```\n",
    "\n",
    "The scraped data was dirtly due to poor organization and requires further cleaning in Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5524ba46-11ea-46ab-9b22-846817607370",
   "metadata": {},
   "source": [
    "2. Remove unnecessary column for \"source URL\" because the values were identical for all the data.\n",
    "3. Renamed column \"gender\" to `Sex` because the actual data reflected sex, not gender identity.\n",
    "4. Use text-to-columns function to expand \"info\" column on the colon (:) to become `Region`, `County`, `Sex`, and `Age` and manually cleaned any mistakes/bad parsing.\n",
    "5. Created a new column `further_info` to identify reports that did not have values for `County`, `Sex`, or `Age` and would require further searching in reports to fill out.\n",
    "6. Aggregate all ages to be in units of 1 year. All stated ages from \"0 days\" to \"12 months\" was recoded as \"<1\". Ages listed as \"12 months\" to \"24 months\" recoded to \"1\". Then removed the word \"year\" after age because all are now in the same unit.\n",
    "7. Clean the `Date` column (for more detail, please reach out for data diary records\n",
    "   1. Identify records where there are missing values and require further information from the report. (764 records)\n",
    "   2. Extract dates from the `report_title` column with formula: `=TEXTJOIN(\"\",TRUE,IFERROR(MID([@[report_title_copy]],ROW(INDIRECT(\"1:\"&LEN([@[report_title_copy]]))),1)*1,\"\"))`\n",
    "   3. Check lenghth of extracted dates to find and then manually fix incorrect dates using formula `=IF(LEN([@[extracted_date]])>6, \"NO\", \"Date\")`\n",
    "   4. Convert the values of the extracted dates into a readable date format with formula `=DATE(20&RIGHT([@[date_num]],2), LEFT([@[date_num]],2), MID([@[date_num]],3,2))`\n",
    "   5. Input new dates into the `Date` column\n",
    "   6. Many dates defaulted to have the year 2024 but the `Year` column did not match (835 records). Parsed month and date together with correct year with formula `=DATE([@year], TEXT([@date],\"MM\"), TEXT([@date],\"DD\"))` and then replaced with the value in `Date` column\n",
    "8. Moved misaligned values back into the `DA_Cert` column\n",
    "9. Ranamed column \"report_url\" to `report_title` to be more intuitively named"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1670d882-3ba4-4875-bd73-336f68c6b2c0",
   "metadata": {},
   "source": [
    "### Parse single report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e710e746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Using cached pdfplumber-0.11.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
      "  Using cached pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting Pillow>=9.1 (from pdfplumber)\n",
      "  Downloading pillow-10.3.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.30.0-py3-none-macosx_11_0_arm64.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer>=2.0.0 (from pdfminer.six==20231228->pdfplumber)\n",
      "  Using cached charset_normalizer-3.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six==20231228->pdfplumber)\n",
      "  Using cached cryptography-42.0.7-cp39-abi3-macosx_10_12_universal2.whl.metadata (5.3 kB)\n",
      "Collecting cffi>=1.12 (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber)\n",
      "  Using cached cffi-1.16.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Using cached pdfplumber-0.11.0-py3-none-any.whl (56 kB)\n",
      "Using cached pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "Downloading pillow-10.3.0-cp312-cp312-macosx_11_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached charset_normalizer-3.3.2-cp312-cp312-macosx_11_0_arm64.whl (119 kB)\n",
      "Using cached cryptography-42.0.7-cp39-abi3-macosx_10_12_universal2.whl (5.9 MB)\n",
      "Using cached cffi-1.16.0-cp312-cp312-macosx_11_0_arm64.whl (177 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: pypdfium2, pycparser, Pillow, charset-normalizer, cffi, cryptography, pdfminer.six, pdfplumber\n",
      "Successfully installed Pillow-10.3.0 cffi-1.16.0 charset-normalizer-3.3.2 cryptography-42.0.7 pdfminer.six-20231228 pdfplumber-0.11.0 pycparser-2.22 pypdfium2-4.30.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec7c9aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m427.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in ./cuaenvironment/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./cuaenvironment/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp312-cp312-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.26.4 pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6ed53b-9a9d-4c54-9b3f-96ed32c9e202",
   "metadata": {},
   "source": [
    "1. Import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c17e0ad5-fb7e-4d7e-bd2d-bddf8b2b380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #regular expressions\n",
    "\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec58718d",
   "metadata": {},
   "source": [
    "2. Create the column names for the data that you are extracting from the pdf. `known` refers to whether the family was known to county DHS in the 16 months before the incident, and `county` identifies which county that was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df312dcd-4239-497e-9ed1-751a4b99ff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "Line = namedtuple('Line', 'known county')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950cc703",
   "metadata": {},
   "source": [
    "3. Create a regular expressions function to parse out `known` and `county`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_re = re.compile(\n",
    "    \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
